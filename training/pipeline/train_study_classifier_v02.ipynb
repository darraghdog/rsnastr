{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/selimsef/dfdc_deepfake_challenge/blob/master/training/pipelines/train_classifier.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import gc\n",
    "import sys\n",
    "import itertools\n",
    "from collections import defaultdict, OrderedDict\n",
    "import platform\n",
    "PATH = '/Users/dhanley/Documents/rsnastr' \\\n",
    "        if platform.system() == 'Darwin' else '/data/rsnastr'\n",
    "os.chdir(PATH)\n",
    "sys.path.append(PATH)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import log_loss\n",
    "from utils.logs import get_logger\n",
    "from utils.utils import RSNAWEIGHTS, RSNA_CFG as CFG\n",
    "from training.tools.config import load_config\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from torch.nn import DataParallel\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.distributed as dist\n",
    "from training.datasets.classifier_dataset import RSNASequenceDataset, collateseqfn, \\\n",
    "        valSeedSampler, examSampler\n",
    "from training.zoo.sequence import SpatialDropout, LSTMNet\n",
    "from training.tools.utils import create_optimizer, AverageMeter, collectPreds, collectLoss\n",
    "from training.tools.utils import splitbatch, unmasklabels, unmasklogits\n",
    "from training.losses import getLoss\n",
    "from training import losses\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(0)\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor\n",
    "logger = get_logger('LSTM', 'INFO') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 21:10:57,659 - LSTM - INFO - Load args\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.argv=['']; del sys\n",
    "logger.info('Load args')\n",
    "parser = argparse.ArgumentParser()\n",
    "arg = parser.add_argument\n",
    "arg('--config', metavar='CONFIG_FILE', help='path to configuration file')\n",
    "arg('--workers', type=int, default=6, help='number of cpu threads to use')\n",
    "arg('--device', type=str, default='cpu' if platform.system() == 'Darwin' else 'cuda', help='device for model - cpu/gpu')\n",
    "arg('--gpu', type=str, default='0', help='List of GPUs for parallel training, e.g. 0,1,2,3')\n",
    "arg('--output-dir', type=str, default='weights/')\n",
    "arg('--resume', type=str, default='')\n",
    "arg('--fold', type=int, default=0)\n",
    "arg('--batchsize', type=int, default=4)\n",
    "arg('--lr', type=float, default = 0.00001)\n",
    "arg('--lrgamma', type=float, default = 0.95)\n",
    "arg('--labeltype', type=str, default='all') # or 'single'\n",
    "arg('--dropout', type=float, default = 0.2)\n",
    "arg('--prefix', type=str, default='classifier_')\n",
    "arg('--data-dir', type=str, default=\"data\")\n",
    "arg('--folds-csv', type=str, default='folds.csv.gz')\n",
    "arg('--nclasses', type=str, default=1)\n",
    "arg('--crops-dir', type=str, default='jpegip')\n",
    "arg('--lstm_units',   type=int, default=512)\n",
    "arg('--epochs',   type=int, default=12)\n",
    "arg('--nbags',   type=int, default=12)\n",
    "arg('--label-smoothing', type=float, default=0.00)\n",
    "arg('--logdir', type=str, default='logs/b2_1820')\n",
    "arg(\"--local_rank\", default=0, type=int)\n",
    "arg(\"--seed\", default=777, type=int)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.lr=0.00001 \n",
    "args.label_smoothing=0.0 \n",
    "args.dropout=0.3\n",
    "args.device='cuda' \n",
    "args.fold=0 \n",
    "args.batchsize=32\n",
    "args.imgembrgx='weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_*__fold*_best_dice__all_size320.emb'\n",
    "args.exmembrgx='weights/exam_lstm_tf_efficientnet_b2_ns_epoch31_fold0.bin__all_size320.emb'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeimg(s):\n",
    "    return s.split('/')[-1].replace('.jpg', '')\n",
    "fimg = sorted(glob.glob(f'emb/{args.imgembrgx}*data.pk'))[0]\n",
    "dfname, embname, imgnm = fimg, fimg.replace('.data.pk', '.npz'), fimg.replace('.data.pk', '.imgnames.pk')\n",
    "imgls = list(map(takeimg, pickle.load( open( imgnm, \"rb\" ) )))\n",
    "wtsname = embname.split('/')[-1].replace('.emb.npz', '')\n",
    "embmat = np.load(embname)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf = pd.read_csv(f'{args.data_dir}/train.csv.zip')\n",
    "datadf = datadf.set_index('SOPInstanceUID').loc[imgls].reset_index()\n",
    "folddf = pd.read_csv(f'{args.data_dir}/{args.folds_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 21:12:56,887 - LSTM - INFO - Create traindatasets\n",
      "2020-10-12 21:12:57,917 - LSTM - INFO - Create valdatasets\n"
     ]
    }
   ],
   "source": [
    "logger.info('Create traindatasets')\n",
    "trndataset = RSNASequenceDataset(datadf, \n",
    "                                   embmat, \n",
    "                                   #embexmmat, \n",
    "                                   folddf,\n",
    "                                   mode=\"train\",\n",
    "                                   imgclasses=CFG[\"image_target_cols\"],\n",
    "                                   studyclasses=CFG['exam_target_cols'],\n",
    "                                   fold=args.fold,\n",
    "                                   label_smoothing=args.label_smoothing,\n",
    "                                   folds_csv=args.folds_csv)\n",
    "logger.info('Create valdatasets')\n",
    "valdataset = RSNASequenceDataset(datadf, \n",
    "                                   embmat, \n",
    "                                   #embexmmat,\n",
    "                                   folddf,\n",
    "                                   mode=\"valid\",\n",
    "                                   imgclasses=CFG[\"image_target_cols\"],\n",
    "                                   studyclasses=CFG['exam_target_cols'],\n",
    "                                   fold=args.fold,\n",
    "                                   label_smoothing=args.label_smoothing,\n",
    "                                   folds_csv=args.folds_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 21:13:07,982 - LSTM - INFO - Create loaders...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info('Create loaders...')\n",
    "valloader = DataLoader(valdataset, batch_size=args.batchsize, shuffle=False, num_workers=4, collate_fn=collateseqfn)\n",
    "embed_size = embmat.shape[1]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 21:13:08,097 - LSTM - INFO - Create model\n"
     ]
    }
   ],
   "source": [
    "logger.info('Create model')\n",
    "model = LSTMNet(embed_size, \n",
    "                       nimgclasses = len(CFG[\"image_target_cols\"]), \n",
    "                       nstudyclasses = len(CFG['exam_target_cols']),\n",
    "                       LSTM_UNITS=args.lstm_units, \n",
    "                       DO = args.dropout)\n",
    "model = model.to(args.device)\n",
    "DECAY = 0.0\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "plist = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': DECAY},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = torch.optim.Adam(plist, lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=args.lrgamma, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredls = []\n",
    "ypredtstls = []\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "bce_func_exam = torch.nn.BCEWithLogitsLoss(reduction='none', \n",
    "                    weight = torch.tensor(CFG['exam_weights']).to(args.device))\n",
    "bce_func_img = torch.nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcewLL_func = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "label_w = torch.tensor([0.0736196319, \n",
    "             0.2346625767, \n",
    "             0.0782208589, \n",
    "             0.06257668712, \n",
    "             0.1042944785, \n",
    "             0.06257668712, \n",
    "             0.1042944785, \n",
    "             0.1877300613, \n",
    "             0.09202453988]).to(args.device, dtype=torch.float)\n",
    "image_w = torch.tensor(0.07361963).to(args.device, dtype=torch.float)\n",
    "\n",
    "def exam_lossfn(studylogits, ystudy, criterion = bcewLL_func):\n",
    "    exam_loss = criterion(studylogits, ystudy)\n",
    "    exam_wts = exam_loss.shape[0]\n",
    "    exam_loss = torch.sum(exam_loss*label_w, 1).sum()\n",
    "    return exam_loss, exam_wts\n",
    "\n",
    "def image_lossfn(imglogits, yimg, mask, criterion = bcewLL_func):\n",
    "    criterion = bcewLL_func\n",
    "    qi = yimg.sum(1)/mask.sum(1)\n",
    "    img_num = mask.sum(1)\n",
    "    image_loss = (criterion(imglogits.squeeze(-1), yimg) * mask).sum(1)\n",
    "    image_loss = torch.sum(image_w*qi*image_loss)\n",
    "    image_wt = torch.sum(image_w*qi*img_num)\n",
    "    return image_loss, image_wt\n",
    "\n",
    "class resultsfn:\n",
    "    loss   = 0.\n",
    "    wts    = 0.\n",
    "    imgloss   = 0.\n",
    "    imgwts    = 0.\n",
    "    exmloss   = 0.\n",
    "    exmwts    = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 21:13:11,235 - LSTM - INFO - Start training\n",
      "Train epoch 0: 182it [03:47,  1.25s/it, train loss=0.386, image loss=0.357, exam loss=0.415]             \n",
      "Valid epoch 0: 46it [00:56,  1.22s/it, valid loss=0.293, image loss=0.285, exam loss=0.301]            \n",
      "2020-10-12 21:17:57,034 - LSTM - INFO - Best Epoch 0 val loss all 0.2929\n",
      "Train epoch 1: 182it [03:44,  1.23s/it, train loss=0.251, image loss=0.238, exam loss=0.263]             \n",
      "Valid epoch 1: 46it [00:55,  1.22s/it, valid loss=0.253, image loss=0.259, exam loss=0.248]            \n",
      "2020-10-12 21:22:39,614 - LSTM - INFO - Best Epoch 1 val loss all 0.2532\n",
      "Train epoch 2: 182it [03:45,  1.24s/it, train loss=0.225, image loss=0.224, exam loss=0.226]             \n",
      "Valid epoch 2: 46it [00:55,  1.22s/it, valid loss=0.247, image loss=0.26, exam loss=0.234]             \n",
      "2020-10-12 21:27:23,195 - LSTM - INFO - Best Epoch 2 val loss all 0.2468\n",
      "Train epoch 3: 182it [03:46,  1.25s/it, train loss=0.218, image loss=0.22, exam loss=0.216]              \n",
      "Valid epoch 3: 46it [00:55,  1.21s/it, valid loss=0.242, image loss=0.255, exam loss=0.229]            \n",
      "2020-10-12 21:32:07,818 - LSTM - INFO - Best Epoch 3 val loss all 0.2420\n",
      "Train epoch 4: 182it [03:47,  1.25s/it, train loss=0.215, image loss=0.217, exam loss=0.212]             \n",
      "Valid epoch 4: 46it [00:56,  1.22s/it, valid loss=0.237, image loss=0.249, exam loss=0.225]            \n",
      "2020-10-12 21:36:53,389 - LSTM - INFO - Best Epoch 4 val loss all 0.2368\n",
      "Train epoch 5: 182it [03:48,  1.26s/it, train loss=0.213, image loss=0.217, exam loss=0.209]             \n",
      "Valid epoch 5: 46it [00:55,  1.21s/it, valid loss=0.236, image loss=0.249, exam loss=0.224]            \n",
      "2020-10-12 21:41:39,456 - LSTM - INFO - Best Epoch 5 val loss all 0.2363\n",
      "Train epoch 6: 182it [04:33,  1.50s/it, train loss=0.211, image loss=0.216, exam loss=0.207]             \n",
      "Valid epoch 6: 46it [00:56,  1.22s/it, valid loss=0.234, image loss=0.246, exam loss=0.223]            \n",
      "2020-10-12 21:47:11,193 - LSTM - INFO - Best Epoch 6 val loss all 0.2343\n",
      "Train epoch 7: 182it [03:55,  1.29s/it, train loss=0.21, image loss=0.215, exam loss=0.206]              \n",
      "Valid epoch 7: 46it [00:55,  1.21s/it, valid loss=0.234, image loss=0.247, exam loss=0.223]            \n",
      "Train epoch 8:  40% 72/181 [01:30<01:17,  1.40it/s, train loss=0.209, image loss=0.214, exam loss=0.204]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bc6c2378739a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrndataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mtrnloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 desc=f\"Train epoch {epoch}\", ncols=0)\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbartrn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mystudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasktrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlelabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0myimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.info('Start training')\n",
    "best_val_loss = 100.\n",
    "from tqdm import tqdm\n",
    "for epoch in range(args.epochs):\n",
    "    examsampler = examSampler(trndataset.datadf, trndataset.folddf)\n",
    "    trnloader = DataLoader(trndataset, batch_size=args.batchsize, sampler = examsampler, num_workers=4, collate_fn=collateseqfn)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.train()  \n",
    "    trnres = resultsfn()\n",
    "    pbartrn = tqdm(enumerate(trnloader), \n",
    "                total = len(trndataset)//trnloader.batch_size, \n",
    "                desc=f\"Train epoch {epoch}\", ncols=0)\n",
    "    for step, batch in pbartrn:\n",
    "        img_names, yimg, ystudy, masktrn, lelabels = splitbatch(batch, args.device)\n",
    "        if yimg.sum()==0: \n",
    "            logger.info('AAAAAA')\n",
    "            continue\n",
    "        xtrn = batch['emb'].to(args.device, dtype=torch.float)\n",
    "        xtrn = torch.autograd.Variable(xtrn, requires_grad=True)\n",
    "        yimg = torch.autograd.Variable(yimg)\n",
    "        ystudy = torch.autograd.Variable(ystudy)\n",
    "        with autocast():\n",
    "            studylogits, imglogits = model(xtrn, masktrn)\n",
    "            exam_loss, exam_wts = exam_lossfn(studylogits, ystudy)\n",
    "            image_loss, image_wts = image_lossfn(imglogits, yimg, masktrn)\n",
    "        loss = (exam_loss+image_loss)/(exam_wts+image_wts)\n",
    "        scaler.scale(loss).backward()\n",
    "        trnres.loss += (exam_loss+image_loss).item()\n",
    "        trnres.wts += (exam_wts+image_wts).item()\n",
    "        trnres.imgloss   += image_loss.item()\n",
    "        trnres.imgwts    += image_wts.item()\n",
    "        trnres.exmloss   += exam_loss.item()\n",
    "        trnres.exmwts    += exam_wts\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        pbartrn.set_postfix({'train loss': trnres.loss/trnres.wts, \n",
    "                          'image loss': trnres.imgloss/trnres.imgwts, \n",
    "                          'exam loss': trnres.exmloss/trnres.exmwts})\n",
    "        \n",
    "        if step%100==0:\n",
    "            torch.cuda.empty_cache()  \n",
    "\n",
    "    #logger.info(f'Epoch {epoch} train loss all {trnres.loss/trnres.wts:.4f}')\n",
    "    output_model_file = f'weights/exam_lstm_{wtsname}__epoch{epoch}.bin'\n",
    "    torch.save(model.state_dict(), output_model_file)\n",
    "    \n",
    "    scheduler.step()\n",
    "    model.eval()  \n",
    "    valres = resultsfn()\n",
    "    pbarval = tqdm(enumerate(valloader), \n",
    "                total = len(valdataset)//valloader.batch_size, \n",
    "                desc=f\"Valid epoch {epoch}\", ncols=0)\n",
    "    for step, batch in pbarval:\n",
    "        img_names, yimg, ystudy, maskval, lelabels = splitbatch(batch, args.device)\n",
    "        if yimg.sum()==0: \n",
    "            logger.info('AAAAAA')\n",
    "            continue\n",
    "        xval = batch['emb'].to(args.device, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            studylogits, imglogits = model(xval, maskval)\n",
    "            exam_loss, exam_wts = exam_lossfn(studylogits, ystudy)\n",
    "            image_loss, image_wts = image_lossfn(imglogits, yimg, maskval)\n",
    "        loss = (exam_loss+image_loss)/(exam_wts+image_wts)\n",
    "        valres.loss += (exam_loss+image_loss).item()\n",
    "        valres.wts += (exam_wts+image_wts).item()\n",
    "        valres.imgloss   += image_loss.item()\n",
    "        valres.imgwts    += image_wts.item()\n",
    "        valres.exmloss   += exam_loss.item()\n",
    "        valres.exmwts    += exam_wts\n",
    "        # logger.info(f'{image_loss.item():.4f}\\t{(img_w*qi*img_num).item():.4f}\\t{exam_loss.item():.4f}\\t{label_w.sum().item():.4f}\\t')\n",
    "        pbarval.set_postfix({'valid loss': valres.loss/valres.wts, \n",
    "                          'image loss': valres.imgloss/valres.imgwts, \n",
    "                          'exam loss': valres.exmloss/valres.exmwts})\n",
    "    val_loss = valres.loss/valres.wts\n",
    "    if best_val_loss>val_loss:\n",
    "        output_model_file = f'weights/exam_lstm_{wtsname}__epoch{epoch}.bin'\n",
    "        torch.save(model.state_dict(), output_model_file)\n",
    "        best_val_loss=val_loss\n",
    "        logger.info(f'Best Epoch {epoch} val loss all {best_val_loss:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
