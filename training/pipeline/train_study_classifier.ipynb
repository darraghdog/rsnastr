{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/selimsef/dfdc_deepfake_challenge/blob/master/training/pipelines/train_classifier.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import gc\n",
    "import sys\n",
    "import itertools\n",
    "from collections import defaultdict, OrderedDict\n",
    "import platform\n",
    "PATH = '/Users/dhanley/Documents/rsnastr' \\\n",
    "        if platform.system() == 'Darwin' else '/data/rsnastr'\n",
    "os.chdir(PATH)\n",
    "sys.path.append(PATH)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import log_loss\n",
    "from utils.logs import get_logger\n",
    "from utils.utils import RSNAWEIGHTS, RSNA_CFG as CFG\n",
    "from training.tools.config import load_config\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from torch.nn import DataParallel\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.distributed as dist\n",
    "from training.datasets.classifier_dataset import RSNASequenceDataset, collateseqfn, \\\n",
    "        valSeedSampler, examSampler\n",
    "from training.zoo.sequence import SpatialDropout, LSTMNet\n",
    "from training.tools.utils import create_optimizer, AverageMeter, collectPreds, collectLoss\n",
    "from training.tools.utils import splitbatch, unmasklabels, unmasklogits\n",
    "from training.losses import getLoss\n",
    "from training import losses\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(0)\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor\n",
    "logger = get_logger('LSTM', 'INFO') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-04 16:04:36,041 - LSTM - INFO - Load args\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.argv=['']; del sys\n",
    "logger.info('Load args')\n",
    "parser = argparse.ArgumentParser()\n",
    "arg = parser.add_argument\n",
    "arg('--config', metavar='CONFIG_FILE', help='path to configuration file')\n",
    "arg('--workers', type=int, default=6, help='number of cpu threads to use')\n",
    "arg('--device', type=str, default='cpu' if platform.system() == 'Darwin' else 'cuda', help='device for model - cpu/gpu')\n",
    "arg('--gpu', type=str, default='0', help='List of GPUs for parallel training, e.g. 0,1,2,3')\n",
    "arg('--output-dir', type=str, default='weights/')\n",
    "arg('--resume', type=str, default='')\n",
    "arg('--fold', type=int, default=0)\n",
    "arg('--batchsize', type=int, default=4)\n",
    "arg('--lr', type=float, default = 0.00001)\n",
    "arg('--lrgamma', type=float, default = 0.95)\n",
    "arg('--labeltype', type=str, default='all') # or 'single'\n",
    "arg('--dropout', type=float, default = 0.2)\n",
    "arg('--prefix', type=str, default='classifier_')\n",
    "arg('--data-dir', type=str, default=\"data\")\n",
    "arg('--folds-csv', type=str, default='folds.csv.gz')\n",
    "arg('--nclasses', type=str, default=1)\n",
    "arg('--crops-dir', type=str, default='jpegip')\n",
    "arg('--lstm_units',   type=int, default=512)\n",
    "arg('--epochs',   type=int, default=12)\n",
    "arg('--nbags',   type=int, default=12)\n",
    "arg('--label-smoothing', type=float, default=0.00)\n",
    "arg('--logdir', type=str, default='logs/b2_1820')\n",
    "arg(\"--local_rank\", default=0, type=int)\n",
    "arg(\"--seed\", default=777, type=int)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emb/weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_0__fold0_best_dice__all_size320.emb.data.pk'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.lr=0.001   \n",
    "args.label_smoothing=0.0  \n",
    "args.device='cuda' \n",
    "args.fold=0 \n",
    "args.batchsize=8\n",
    "args.embrgx='weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_*__fold*_best_dice__hflip0_transpose0_size320.emb' \n",
    "args.embrgx='weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_*__fold*_best_dice__all_size320.emb'\n",
    "datals = sorted(glob.glob(f'emb/{args.embrgx}*data.pk'))\n",
    "datals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-04 16:04:36,124 - LSTM - INFO - File load : emb/weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_0__fold0_best_dice__all_size320.emb.data.pk\n"
     ]
    }
   ],
   "source": [
    "def takeimg(s):\n",
    "    return s.split('/')[-1].replace('.jpg', '')\n",
    "f=datals[0]\n",
    "logger.info(f'File load : {f}')\n",
    "dfname, embname, imgnm = f, f.replace('.data.pk', '.npz'), f.replace('.data.pk', '.imgnames.pk')\n",
    "datadf = pd.read_pickle(dfname)\n",
    "embmat = np.load(embname)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgls = list(map(takeimg, pickle.load( open( imgnm, \"rb\" ) )))\n",
    "datadf = pd.read_csv(f'{args.data_dir}/train.csv.zip')\n",
    "datadf = datadf.set_index('SOPInstanceUID').loc[imgls].reset_index()\n",
    "folddf = pd.read_csv(f'{args.data_dir}/{args.folds_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1790593, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SOPInstanceUID                c0f3cb036d06\n",
       "StudyInstanceUID              6897fa9de148\n",
       "SeriesInstanceUID             2bfbb7fd2e8b\n",
       "pe_present_on_image                      0\n",
       "negative_exam_for_pe                     0\n",
       "qa_motion                                0\n",
       "qa_contrast                              0\n",
       "flow_artifact                            0\n",
       "rv_lv_ratio_gte_1                        0\n",
       "rv_lv_ratio_lt_1                         1\n",
       "leftsided_pe                             1\n",
       "chronic_pe                               0\n",
       "true_filling_defect_not_pe               0\n",
       "rightsided_pe                            1\n",
       "acute_and_chronic_pe                     0\n",
       "central_pe                               0\n",
       "indeterminate                            0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datadf.shape)\n",
    "datadf.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-04 16:09:02,386 - LSTM - INFO - Create traindatasets\n",
      "2020-10-04 16:09:04,713 - LSTM - INFO - Create valdatasets\n"
     ]
    }
   ],
   "source": [
    "logger.info('Create traindatasets')\n",
    "trndataset = RSNASequenceDataset(datadf, \n",
    "                                   embmat, \n",
    "                                   folddf,\n",
    "                                   mode=\"train\",\n",
    "                                   imgclasses=CFG[\"image_target_cols\"],\n",
    "                                   studyclasses=CFG['exam_target_cols'],\n",
    "                                   fold=args.fold,\n",
    "                                   label_smoothing=args.label_smoothing,\n",
    "                                   folds_csv=args.folds_csv)\n",
    "logger.info('Create valdatasets')\n",
    "valdataset = RSNASequenceDataset(datadf, \n",
    "                                   embmat, \n",
    "                                   folddf,\n",
    "                                   mode=\"valid\",\n",
    "                                   imgclasses=CFG[\"image_target_cols\"],\n",
    "                                   studyclasses=CFG['exam_target_cols'],\n",
    "                                   fold=args.fold,\n",
    "                                   label_smoothing=args.label_smoothing,\n",
    "                                   folds_csv=args.folds_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-04 16:09:06,469 - LSTM - INFO - Create loaders...\n",
      "2020-10-04 16:09:06,612 - LSTM - INFO - Create model\n"
     ]
    }
   ],
   "source": [
    "logger.info('Create loaders...')\n",
    "valloader = DataLoader(valdataset, batch_size=args.batchsize*8, shuffle=False, num_workers=4, collate_fn=collateseqfn)\n",
    "embed_size = embmat.shape[1]\n",
    "# del embmat\n",
    "gc.collect()\n",
    "\n",
    "logger.info('Create model')\n",
    "model = LSTMNet(embed_size, \n",
    "                       nimgclasses = len(CFG[\"image_target_cols\"]), \n",
    "                       nstudyclasses = len(CFG['exam_target_cols']),\n",
    "                       LSTM_UNITS=args.lstm_units, \n",
    "                       DO = args.dropout)\n",
    "model = model.to(args.device)\n",
    "DECAY = 0.0\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "plist = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': DECAY},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = torch.optim.Adam(plist, lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=args.lrgamma, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredls = []\n",
    "ypredtstls = []\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "bce_func_exam = torch.nn.BCEWithLogitsLoss(reduction='none', \n",
    "                    weight = torch.tensor(CFG['exam_weights']).to(args.device))\n",
    "bce_func_img = torch.nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupBy(samples, labels, unique_labels, labels_count, grptype = 'mean'):\n",
    "    res = torch.zeros_like(unique_labels, dtype=torch.float).scatter_add_(0, labels, samples)\n",
    "    if grptype == 'sum':\n",
    "        return res\n",
    "    if grptype == 'mean':\n",
    "        res = res / labels_count.float().unsqueeze(1)\n",
    "        return res\n",
    "    \n",
    "def rsna_criterion_all(y_pred_exam_, \n",
    "                   y_true_exam_, \n",
    "                   y_pred_img_, \n",
    "                   y_true_img_,\n",
    "                   le_study, \n",
    "                   img_wt):\n",
    "    # Groupby \n",
    "    labels = le_study.view(le_study.size(0), 1).expand(-1, 1)\n",
    "    unique_labels, labels_count = labels.unique(dim=0, return_counts=True)\n",
    "    \n",
    "    #logger.info('Exam loss')\n",
    "    exam_loss = bce_func_exam(y_pred_exam_, y_true_exam_)\n",
    "    exam_loss = exam_loss.sum(1).unsqueeze(1)\n",
    "    exam_loss = groupBy(exam_loss, labels, unique_labels, labels_count, grptype = 'mean').sum()\n",
    "    exam_wts = torch.tensor(le_study.unique().shape[0]).float()\n",
    "    \n",
    "    #logger.info('Image loss')\n",
    "    image_loss = bce_func_img(y_pred_img_, y_true_img_)\n",
    "    image_loss = groupBy(image_loss, labels, unique_labels, labels_count, grptype = 'sum')\n",
    "    qi_all = groupBy(y_true_img_, labels, unique_labels, labels_count, grptype = 'mean')\n",
    "    image_loss = (img_wt * qi_all * image_loss).sum()\n",
    "    img_wts = (img_wt * y_true_img_).sum()\n",
    "    \n",
    "    #logger.info('Final loss')\n",
    "    img_loss_out =  image_loss / img_wts\n",
    "    exam_loss_out = exam_loss / exam_wts\n",
    "    final_loss = (image_loss + exam_loss)/(img_wts + exam_wts)\n",
    "    return final_loss , img_loss_out, exam_loss_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-04 16:13:09,892 - LSTM - INFO - Start training\n",
      "2020-10-04 16:13:11,545 - LSTM - INFO - --------------------------------------------------\n",
      "2020-10-04 16:13:14,809 - LSTM - INFO - LOOP:train step 2 of 728 trn loss 0.1701 img loss 0.0855 exam loss 0.1966\n",
      "2020-10-04 16:13:32,885 - LSTM - INFO - LOOP:train step 52 of 728 trn loss 0.2964 img loss 0.2027 exam loss 0.3766\n",
      "2020-10-04 16:13:52,436 - LSTM - INFO - LOOP:train step 102 of 728 trn loss 0.2941 img loss 0.2012 exam loss 0.3697\n",
      "2020-10-04 16:14:10,381 - LSTM - INFO - LOOP:train step 152 of 728 trn loss 0.2994 img loss 0.2134 exam loss 0.3721\n",
      "2020-10-04 16:14:29,425 - LSTM - INFO - LOOP:train step 202 of 728 trn loss 0.2990 img loss 0.2134 exam loss 0.3753\n",
      "2020-10-04 16:14:48,991 - LSTM - INFO - LOOP:train step 252 of 728 trn loss 0.3005 img loss 0.2162 exam loss 0.3758\n",
      "2020-10-04 16:15:06,852 - LSTM - INFO - LOOP:train step 302 of 728 trn loss 0.3021 img loss 0.2185 exam loss 0.3762\n",
      "2020-10-04 16:15:24,011 - LSTM - INFO - LOOP:train step 352 of 728 trn loss 0.3008 img loss 0.2161 exam loss 0.3760\n",
      "2020-10-04 16:15:42,977 - LSTM - INFO - LOOP:train step 402 of 728 trn loss 0.3005 img loss 0.2155 exam loss 0.3755\n",
      "2020-10-04 16:16:01,933 - LSTM - INFO - LOOP:train step 452 of 728 trn loss 0.3008 img loss 0.2168 exam loss 0.3754\n",
      "2020-10-04 16:16:08,354 - LSTM - INFO - AAAAAA\n",
      "2020-10-04 16:16:20,871 - LSTM - INFO - LOOP:train step 501 of 728 trn loss 0.3000 img loss 0.2149 exam loss 0.3765\n",
      "2020-10-04 16:16:29,470 - LSTM - INFO - AAAAAA\n",
      "2020-10-04 16:16:39,137 - LSTM - INFO - LOOP:train step 550 of 728 trn loss 0.3007 img loss 0.2162 exam loss 0.3766\n",
      "2020-10-04 16:16:57,257 - LSTM - INFO - LOOP:train step 600 of 728 trn loss 0.3018 img loss 0.2181 exam loss 0.3763\n",
      "2020-10-04 16:17:16,934 - LSTM - INFO - LOOP:train step 650 of 728 trn loss 0.3021 img loss 0.2194 exam loss 0.3762\n",
      "2020-10-04 16:17:27,406 - LSTM - INFO - AAAAAA\n",
      "2020-10-04 16:17:35,159 - LSTM - INFO - LOOP:train step 699 of 728 trn loss 0.3019 img loss 0.2181 exam loss 0.3762\n",
      "2020-10-04 16:17:44,019 - LSTM - INFO - Train loss all 0.2991 img 0.2199 exam 0.3769\n",
      "2020-10-04 16:17:44,020 - LSTM - INFO - --------------------------------------------------\n",
      "2020-10-04 16:17:44,021 - LSTM - INFO - Prep test sub...\n",
      "2020-10-04 16:19:00,045 - LSTM - INFO - Valid loss all 0.3140 img 0.2441 exam 0.3813\n",
      "2020-10-04 16:19:01,087 - LSTM - INFO - --------------------------------------------------\n",
      "2020-10-04 16:19:04,358 - LSTM - INFO - LOOP:train step 2 of 728 trn loss 0.1414 img loss 0.1050 exam loss 0.1826\n",
      "2020-10-04 16:19:22,043 - LSTM - INFO - LOOP:train step 52 of 728 trn loss 0.2891 img loss 0.2047 exam loss 0.3622\n",
      "2020-10-04 16:19:41,477 - LSTM - INFO - LOOP:train step 102 of 728 trn loss 0.2901 img loss 0.2073 exam loss 0.3697\n",
      "2020-10-04 16:19:56,507 - LSTM - INFO - AAAAAA\n",
      "2020-10-04 16:19:58,930 - LSTM - INFO - LOOP:train step 151 of 728 trn loss 0.2966 img loss 0.2152 exam loss 0.3717\n",
      "2020-10-04 16:20:18,142 - LSTM - INFO - LOOP:train step 201 of 728 trn loss 0.2961 img loss 0.2129 exam loss 0.3736\n"
     ]
    }
   ],
   "source": [
    "logger.info('Start training')\n",
    "for epoch in range(args.epochs):\n",
    "    examsampler = examSampler(trndataset.datadf, trndataset.folddf)\n",
    "    trnloader = DataLoader(trndataset, batch_size=args.batchsize, sampler = examsampler, num_workers=4, collate_fn=collateseqfn)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.train()  \n",
    "    img_wt = torch.tensor(CFG['image_weight']).to(args.device, dtype=torch.float)\n",
    "    trncollect = collectPreds()\n",
    "    valcollect = collectPreds()\n",
    "    trnloss = collectLoss(trnloader, mode = 'train')\n",
    "    valloss = collectLoss(valloader, mode = 'valid')\n",
    "    logger.info(50*'-')\n",
    "    for step, batch in enumerate(trnloader):\n",
    "        img_names, yimg, ystudy, masktrn, lelabels = splitbatch(batch, args.device)\n",
    "        if yimg.sum()==0: \n",
    "            logger.info('AAAAAA')\n",
    "            continue\n",
    "        xtrn = batch['emb'].to(args.device, dtype=torch.float)\n",
    "        xtrn = torch.autograd.Variable(xtrn, requires_grad=True)\n",
    "        yimg = torch.autograd.Variable(yimg)\n",
    "        ystudy = torch.autograd.Variable(ystudy)\n",
    "        with autocast():\n",
    "            studylogits, imglogits = model(xtrn, masktrn)#.to(args.device, dtype=torch.float)\n",
    "            yimg, ystudy, lelabels, img_names = unmasklabels(yimg, ystudy, lelabels, img_names, masktrn)\n",
    "            imglogits, studylogits = unmasklogits(imglogits, studylogits, masktrn)\n",
    "            # Loss function\n",
    "            loss, img_loss, exam_loss = rsna_criterion_all(studylogits, \n",
    "                                                       ystudy, \n",
    "                                                       imglogits, \n",
    "                                                       yimg, \n",
    "                                                       lelabels, \n",
    "                                                       img_wt)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        trncollect.append(img_names, lelabels, imglogits, studylogits, yimg, ystudy)\n",
    "        trnloss.increment(loss, img_loss, exam_loss)\n",
    "        if step % 50==0: logger.info(f'LOOP:{trnloss.log()}')\n",
    "    trn_loss, trn_img_loss, trn_exam_loss = rsna_criterion_all(*trncollect.concat(args.device), img_wt)\n",
    "    logger.info(f'Train loss all {trn_loss:.4f} img {trn_img_loss:.4f} exam {trn_exam_loss:.4f}')\n",
    "    logger.info(50*'-')\n",
    "    scheduler.step()\n",
    "    logger.info('Prep test sub...')\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(valloader):\n",
    "        img_names, yimg, ystudy, maskval, lelabels = splitbatch(batch, args.device)\n",
    "        xval = batch['emb'].to(args.device, dtype=torch.float)\n",
    "        studylogits, imglogits = model(xval, maskval)#.to(args.device, dtype=torch.float)\n",
    "        # Repeat studies to have a prediction for every image\n",
    "        yimg, ystudy, lelabels, img_names = unmasklabels(yimg, ystudy, lelabels, img_names, maskval)\n",
    "        imglogits, studylogits = unmasklogits(imglogits, studylogits, maskval)\n",
    "        loss, img_loss, exam_loss = rsna_criterion_all(studylogits, \n",
    "                                                   ystudy, \n",
    "                                                   imglogits, \n",
    "                                                   yimg, \n",
    "                                                   lelabels, \n",
    "                                                   img_wt)\n",
    "        valcollect.append(img_names, lelabels, imglogits, studylogits, yimg, ystudy)\n",
    "        valloss.increment(loss, img_loss, exam_loss)\n",
    "    val_loss, val_img_loss, val_exam_loss = rsna_criterion_all(*valcollect.concat(args.device), img_wt)\n",
    "    logger.info(f'Valid loss all {val_loss:.4f} img {val_img_loss:.4f} exam {val_exam_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trncollect.series('img_names').shape)\n",
    "print(trncollect.series('study_labels').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myseries(collect, feat):\n",
    "    return torch.sigmoid(collect.series(feat).float().cpu()).numpy()\n",
    "\n",
    "trnpreds = pd.DataFrame(np.concatenate((myseries(trncollect, 'img_preds'), \n",
    "                    myseries(trncollect, 'study_preds')), 1),\n",
    "                    columns = CFG['image_target_cols']+CFG['exam_target_cols'], \n",
    "                    index = trncollect.series('img_names'))\n",
    "valpreds = pd.DataFrame(np.concatenate((myseries(valcollect, 'img_preds'), \n",
    "                    myseries(valcollect, 'study_preds')), 1),\n",
    "                    columns = CFG['image_target_cols']+CFG['exam_target_cols'], \n",
    "                    index = valcollect.series('img_names'))   \n",
    "valpreds.hist(figsize = (25,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnpreds.hist(figsize = (25,25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valpreds.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valpreds.tail(1).index)\n",
    "print(xval[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trnpreds.tail(1).index)\n",
    "print(xtrn[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = datals[0]\n",
    "logger.info(f'File load : {f}')\n",
    "dfname, embname, imgnm = f, f.replace('.data.pk', '.npz'), f.replace('.data.pk', '.imgnames.pk')\n",
    "datadf = pd.read_pickle(dfname)\n",
    "embmat = np.load(embname)['arr_0']\n",
    "embmat = embmat[np.where(datadf.SOPInstanceUID=='32ec58af84d9')[0]]\n",
    "embmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = datals[1]\n",
    "logger.info(f'File load : {f}')\n",
    "dfname, embname, imgnm = f, f.replace('.data.pk', '.npz'), f.replace('.data.pk', '.imgnames.pk')\n",
    "datadf = pd.read_pickle(dfname)\n",
    "embmat = np.load(embname)['arr_0']\n",
    "embmat = embmat[np.where(datadf.SOPInstanceUID=='dba5502f56b7')[0]]\n",
    "embmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masktrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval.mean(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn.mean(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
