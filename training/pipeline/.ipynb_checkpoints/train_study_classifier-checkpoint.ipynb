{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/selimsef/dfdc_deepfake_challenge/blob/master/training/pipelines/train_classifier.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import gc\n",
    "import sys\n",
    "import itertools\n",
    "from collections import defaultdict, OrderedDict\n",
    "import platform\n",
    "PATH = '/Users/dhanley/Documents/rsnastr' \\\n",
    "        if platform.system() == 'Darwin' else '/data/rsnastr'\n",
    "os.chdir(PATH)\n",
    "sys.path.append(PATH)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import log_loss\n",
    "from utils.logs import get_logger\n",
    "from utils.utils import RSNAWEIGHTS, RSNA_CFG as CFG\n",
    "from training.tools.config import load_config\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from torch.nn import DataParallel\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.distributed as dist\n",
    "from training.datasets.classifier_dataset import RSNASequenceDataset, collateseqfn, \\\n",
    "        valSeedSampler\n",
    "from training.zoo.sequence import SpatialDropout, LSTMNet\n",
    "from training.tools.utils import create_optimizer, AverageMeter\n",
    "from training.losses import getLoss\n",
    "from training import losses\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(0)\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor\n",
    "logger = get_logger('LSTM', 'INFO') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-03 22:20:27,501 - LSTM - INFO - Load args\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.argv=['']; del sys\n",
    "logger.info('Load args')\n",
    "parser = argparse.ArgumentParser()\n",
    "arg = parser.add_argument\n",
    "arg('--config', metavar='CONFIG_FILE', help='path to configuration file')\n",
    "arg('--workers', type=int, default=6, help='number of cpu threads to use')\n",
    "arg('--device', type=str, default='cpu' if platform.system() == 'Darwin' else 'cuda', help='device for model - cpu/gpu')\n",
    "arg('--gpu', type=str, default='0', help='List of GPUs for parallel training, e.g. 0,1,2,3')\n",
    "arg('--output-dir', type=str, default='weights/')\n",
    "arg('--resume', type=str, default='')\n",
    "arg('--fold', type=int, default=0)\n",
    "arg('--batchsize', type=int, default=4)\n",
    "arg('--lr', type=float, default = 0.00001)\n",
    "arg('--lrgamma', type=float, default = 0.95)\n",
    "arg('--labeltype', type=str, default='all') # or 'single'\n",
    "arg('--dropout', type=float, default = 0.2)\n",
    "arg('--prefix', type=str, default='classifier_')\n",
    "arg('--data-dir', type=str, default=\"data\")\n",
    "arg('--folds-csv', type=str, default='folds.csv.gz')\n",
    "arg('--nclasses', type=str, default=1)\n",
    "arg('--crops-dir', type=str, default='jpegip')\n",
    "arg('--lstm_units',   type=int, default=512)\n",
    "arg('--epochs',   type=int, default=12)\n",
    "arg('--nbags',   type=int, default=12)\n",
    "arg('--label-smoothing', type=float, default=0.00)\n",
    "arg('--logdir', type=str, default='logs/b2_1820')\n",
    "arg(\"--local_rank\", default=0, type=int)\n",
    "arg(\"--seed\", default=777, type=int)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.lr=0.0001   \n",
    "args.label_smoothing=0.0  \n",
    "args.device='cuda' \n",
    "args.fold=0 \n",
    "args.batchsize=4\n",
    "args.embrgx='weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_*__fold*_best_dice__hflip0_transpose0_size320.emb' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-03 22:20:27,528 - LSTM - INFO - File load : emb/weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_0__fold0_best_dice__hflip0_transpose0_size320.emb.data.pk\n",
      "2020-10-03 22:20:51,268 - LSTM - INFO - Embedding shape : (359209, 2048)\n",
      "2020-10-03 22:20:51,269 - LSTM - INFO - DataFrame shape : (359209, 17)\n",
      "2020-10-03 22:20:51,269 - LSTM - INFO - DataFrame shape : 359209\n",
      "2020-10-03 22:20:51,338 - LSTM - INFO - File load : emb/weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_1__fold1_best_dice__hflip0_transpose0_size320.emb.data.pk\n",
      "2020-10-03 22:21:16,922 - LSTM - INFO - Embedding shape : (715642, 2048)\n",
      "2020-10-03 22:21:16,923 - LSTM - INFO - DataFrame shape : (715642, 17)\n",
      "2020-10-03 22:21:16,923 - LSTM - INFO - DataFrame shape : 715642\n",
      "2020-10-03 22:21:16,996 - LSTM - INFO - File load : emb/weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_2__fold2_best_dice__hflip0_transpose0_size320.emb.data.pk\n",
      "2020-10-03 22:21:44,379 - LSTM - INFO - Embedding shape : (1072105, 2048)\n",
      "2020-10-03 22:21:44,380 - LSTM - INFO - DataFrame shape : (1072106, 17)\n",
      "2020-10-03 22:21:44,381 - LSTM - INFO - DataFrame shape : 1072105\n",
      "2020-10-03 22:21:44,457 - LSTM - INFO - File load : emb/weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_3__fold3_best_dice__hflip0_transpose0_size320.emb.data.pk\n",
      "2020-10-03 22:22:13,478 - LSTM - INFO - Embedding shape : (1429402, 2048)\n",
      "2020-10-03 22:22:13,479 - LSTM - INFO - DataFrame shape : (1429403, 17)\n",
      "2020-10-03 22:22:13,479 - LSTM - INFO - DataFrame shape : 1429402\n",
      "2020-10-03 22:22:13,565 - LSTM - INFO - File load : emb/weights/classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_4__fold4_best_dice__hflip0_transpose0_size320.emb.data.pk\n",
      "2020-10-03 22:22:43,288 - LSTM - INFO - Embedding shape : (1790593, 2048)\n",
      "2020-10-03 22:22:43,289 - LSTM - INFO - DataFrame shape : (1790594, 17)\n",
      "2020-10-03 22:22:43,290 - LSTM - INFO - DataFrame shape : 1790593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SOPInstanceUID                c0f3cb036d06\n",
       "StudyInstanceUID              6897fa9de148\n",
       "SeriesInstanceUID             2bfbb7fd2e8b\n",
       "pe_present_on_image                      0\n",
       "negative_exam_for_pe                     0\n",
       "qa_motion                                0\n",
       "qa_contrast                              0\n",
       "flow_artifact                            0\n",
       "rv_lv_ratio_gte_1                        0\n",
       "rv_lv_ratio_lt_1                         1\n",
       "leftsided_pe                             1\n",
       "chronic_pe                               0\n",
       "true_filling_defect_not_pe               0\n",
       "rightsided_pe                            1\n",
       "acute_and_chronic_pe                     0\n",
       "central_pe                               0\n",
       "indeterminate                            0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def takeimg(s):\n",
    "    return s.split('/')[-1].replace('.jpg', '')\n",
    "#embrgx = 'classifier_RSNAClassifier_resnext101_32x8d_*__fold*_epoch24__hflip*_transpose0_size320.emb'\n",
    "#embrgx = 'classifier_RSNAClassifier_tf_efficientnet_b5_ns_04d_*__fold*_epoch24__hflip0_transpose0_size320.emb'\n",
    "datals = sorted(glob.glob(f'emb/{args.embrgx}*data.pk'))\n",
    "imgls = []\n",
    "for i, f in enumerate(datals):\n",
    "    logger.info(f'File load : {f}')\n",
    "    dfname, embname, imgnm = f, f.replace('.data.pk', '.npz'), f.replace('.data.pk', '.imgnames.pk')\n",
    "    if i == 0:\n",
    "        datadf = pd.read_pickle(dfname)\n",
    "        embmat = np.load(embname)['arr_0']\n",
    "    if i>0:\n",
    "        embmat = np.append( embmat, np.load(embname)['arr_0'], 0)\n",
    "        datadf = pd.concat([datadf, pd.read_pickle(dfname)], 0)\n",
    "    imgls += list(map(takeimg, pickle.load( open( imgnm, \"rb\" ) )))\n",
    "    logger.info(f'Embedding shape : {embmat.shape}')\n",
    "    logger.info(f'DataFrame shape : {datadf.shape}')\n",
    "    logger.info(f'DataFrame shape : {len(imgls)}')\n",
    "    gc.collect()\n",
    "folddf = pd.read_csv(f'{args.data_dir}/{args.folds_csv}')\n",
    "datadf = datadf.set_index('SOPInstanceUID').loc[imgls].reset_index()\n",
    "datadf.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-03 22:22:47,454 - LSTM - INFO - Create traindatasets\n",
      "2020-10-03 22:22:48,530 - LSTM - INFO - Create valdatasets\n",
      "2020-10-03 22:22:49,407 - LSTM - INFO - Create loaders...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info('Create traindatasets')\n",
    "trndataset = RSNASequenceDataset(datadf, \n",
    "                                   embmat, \n",
    "                                   folddf,\n",
    "                                   mode=\"train\",\n",
    "                                   imgclasses=CFG[\"image_target_cols\"],\n",
    "                                   studyclasses=CFG['exam_target_cols'],\n",
    "                                   fold=args.fold,\n",
    "                                   label_smoothing=args.label_smoothing,\n",
    "                                   folds_csv=args.folds_csv)\n",
    "logger.info('Create valdatasets')\n",
    "valdataset = RSNASequenceDataset(datadf, \n",
    "                                   embmat, \n",
    "                                   folddf,\n",
    "                                   mode=\"valid\",\n",
    "                                   imgclasses=CFG[\"image_target_cols\"],\n",
    "                                   studyclasses=CFG['exam_target_cols'],\n",
    "                                   fold=args.fold,\n",
    "                                   label_smoothing=args.label_smoothing,\n",
    "                                   folds_csv=args.folds_csv)\n",
    "\n",
    "logger.info('Create loaders...')\n",
    "trnloader = DataLoader(trndataset, batch_size=args.batchsize, shuffle=True, num_workers=4, collate_fn=collateseqfn)\n",
    "valloader = DataLoader(valdataset, batch_size=args.batchsize*8, shuffle=False, num_workers=4, collate_fn=collateseqfn)\n",
    "embed_size = embmat.shape[1]\n",
    "del embmat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-03 22:35:32,897 - LSTM - INFO - Create model\n"
     ]
    }
   ],
   "source": [
    "logger.info('Create model')\n",
    "model = LSTMNet(embed_size, \n",
    "                       nimgclasses = len(CFG[\"image_target_cols\"]), \n",
    "                       nstudyclasses = len(CFG['exam_target_cols']),\n",
    "                       LSTM_UNITS=args.lstm_units, \n",
    "                       DO = args.dropout)\n",
    "model = model.to(args.device)\n",
    "DECAY = 0.0\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "plist = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': DECAY},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = torch.optim.Adam(plist, lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=args.lrgamma, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredls = []\n",
    "ypredtstls = []\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "bce_func_exam = torch.nn.BCEWithLogitsLoss(reduction='none', \n",
    "                    weight = torch.tensor(CFG['exam_weights']).to(args.device))\n",
    "bce_func_img = torch.nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupBy(samples, labels, unique_labels, labels_count, grptype = 'mean'):\n",
    "    res = torch.zeros_like(unique_labels, dtype=torch.float).scatter_add_(0, labels, samples)\n",
    "    if grptype == 'sum':\n",
    "        return res\n",
    "    if grptype == 'mean':\n",
    "        res = res / labels_count.float().unsqueeze(1)\n",
    "        return res\n",
    "\n",
    "def rsna_criterion(y_pred_exam_, \n",
    "                   y_true_exam_, \n",
    "                   y_pred_img_, \n",
    "                   y_true_img_,\n",
    "                   le_study, \n",
    "                   img_wt,\n",
    "                   verbose = False):\n",
    "    # Groupby \n",
    "    labels = le_study.view(le_study.size(0), 1).expand(-1, 1)\n",
    "    unique_labels, labels_count = labels.unique(dim=0, return_counts=True)\n",
    "    \n",
    "    #logger.info('Exam loss')\n",
    "    exam_loss = bce_func_exam(y_pred_exam_, y_true_exam_)\n",
    "    exam_loss = exam_loss.sum(1).unsqueeze(1)\n",
    "    exam_loss = groupBy(exam_loss, labels, unique_labels, labels_count, grptype = 'mean').sum()\n",
    "    exam_wts = torch.tensor(le_study.unique().shape[0]).float()\n",
    "    \n",
    "    \n",
    "    #logger.info('Image loss')\n",
    "    image_loss = bce_func_img(y_pred_img_, y_true_img_)\n",
    "    image_loss = groupBy(image_loss, labels, unique_labels, labels_count, grptype = 'sum')\n",
    "    \n",
    "    qi_all = groupBy(y_true_img_, labels, unique_labels, labels_count, grptype = 'mean')\n",
    "    \n",
    "    img_wts = img_wt * (y_true_img_).sum()\n",
    "    #if verbose and (img_wts==0):\n",
    "    #    logger.info((qi_all * image_loss.detach()).sum())\n",
    "        \n",
    "    img_loss = img_wt * (qi_all * image_loss.detach()).sum()\n",
    "            \n",
    "    #logger.info('Final loss')\n",
    "    img_loss_out = img_loss if (img_loss == img_wts == 0) else img_loss / img_wts\n",
    "    exam_loss_out = exam_loss / exam_wts\n",
    "    final_loss = (img_loss + exam_loss)/(img_wts + exam_wts)\n",
    "    if verbose:\n",
    "        log = f'Final loss {final_loss:.3f} img loss {img_loss_out:.3f} wt {img_wts:.3f}'\n",
    "        log += f' exam loss {exam_loss_out:.3f} wt {exam_wts:.3f}'\n",
    "        logger.info(log)\n",
    "        logger.info(50*'-')\n",
    "        \n",
    "    return final_loss, img_loss_out, exam_loss_out\n",
    "\n",
    "\n",
    "def splitbatch(batch, device):\n",
    "    img_names = batch['img_name']\n",
    "    yimg = batch['imglabels'].to(args.device, dtype=torch.float)\n",
    "    ystudy = batch['studylabels'].to(args.device, dtype=torch.float)\n",
    "    mask = batch['mask'].to(args.device, dtype=torch.int)\n",
    "    lelabels = batch['lelabels'].to(args.device, dtype=torch.int64)\n",
    "    return img_names, yimg, ystudy, mask, lelabels\n",
    "\n",
    "def unmasklabels(yimg, ystudy, lelabels, img_names, mask):\n",
    "    ystudy = ystudy.unsqueeze(2).repeat(1, 1, imglogits.size(1))\n",
    "    ystudy = ystudy.transpose(2, 1)\n",
    "    # get the mask for masked img labels\n",
    "    maskidx = mask.view(-1)==1\n",
    "    # Flatten them all along batch and seq dimension and remove masked values\n",
    "    yimg = yimg.view(-1, 1)[maskidx]\n",
    "    ystudy = ystudy.reshape(-1, ystudy.size(-1))[maskidx]\n",
    "    lelabels = lelabels.view(-1, 1)[maskidx] \n",
    "    lelabels = lelabels.flatten()\n",
    "    img_names = img_names.flatten()[maskidx.detach().cpu().numpy()]\n",
    "    return yimg, ystudy, lelabels, img_names\n",
    "    \n",
    "def unmasklogits(imglogits, studylogits, mask):\n",
    "    imglogits = imglogits.squeeze()\n",
    "    studylogits = studylogits.unsqueeze(2).repeat(1, 1, imglogits.size(1))\n",
    "    # get the mask for masked img labels\n",
    "    maskidx = mask.view(-1)==1\n",
    "    # Flatten them all along batch and seq dimension and remove masked values\n",
    "    imglogits = imglogits.view(-1, 1)[maskidx]\n",
    "    studylogits = studylogits.reshape(-1, ystudy.size(-1))[maskidx]\n",
    "    return imglogits, studylogits\n",
    "\n",
    "class collectPreds:\n",
    "    def __init__(self):\n",
    "        self.lelabelsls = []\n",
    "        self.imgnamesls = []\n",
    "        self.imgpredsls = []\n",
    "        self.imglabells = []\n",
    "        self.studylabells = []\n",
    "        self.studypredsls = []\n",
    "        self.maxlelabel = 0\n",
    "\n",
    "    def append(self, img_names, lelabels, imgpreds, studypreds, yimg, ystudy):\n",
    "        lelabels = lelabels.detach().cpu()\n",
    "        if len(self.lelabelsls)>0:\n",
    "            increment = self.lelabelsls[-1].max() + torch.tensor(1).cpu()\n",
    "            lelabels = lelabels + increment\n",
    "        self.lelabelsls.append(lelabels)\n",
    "        self.imgpredsls.append(imglogits.detach().cpu())\n",
    "        self.imglabells.append(yimg.detach().cpu())\n",
    "        self.studylabells.append(ystudy.detach().cpu())\n",
    "        self.studypredsls.append(studylogits.detach().cpu())\n",
    "        self.imgnamesls.append(img_names)\n",
    "\n",
    "    def concat(self, device):\n",
    "        lelabels = torch.cat(self.lelabelsls).to(device)\n",
    "        imgpreds = torch.cat(self.imgpredsls).to(device)\n",
    "        imglabels = torch.cat(self.imglabells).to(device)\n",
    "        studylabels = torch.cat(self.studylabells).to(device)\n",
    "        studypreds = torch.cat(self.studypredsls).to(device)\n",
    "        return studypreds, studylabels, imgpreds, imglabels, lelabels\n",
    "    \n",
    "    def series(self, series):\n",
    "        if series=='lelabels': return torch.cat(self.lelabelsls)\n",
    "        if series=='img_preds': return torch.cat(self.imgpredsls)\n",
    "        if series=='img_labels': return torch.cat(self.imglabells)\n",
    "        if series=='study_labels': return torch.cat(self.studylabells)\n",
    "        if series=='study_preds': return torch.cat(self.studypredsls)\n",
    "        if series=='img_names': return np.concatenate(self.imgnamesls)\n",
    "\n",
    "class collectLoss:\n",
    "    def __init__(self, loader, mode = 'train'):\n",
    "        self.mode = mode\n",
    "        self.loss = 0.\n",
    "        self.img_loss = 0.\n",
    "        self.exam_loss = 0.\n",
    "        self.step = 1\n",
    "        self.loaderlen = len(loader)\n",
    "\n",
    "    def increment(self, loss, img_loss, exam_loss):\n",
    "        self.loss += loss.item()\n",
    "        self.img_loss += img_loss.item()\n",
    "        self.exam_loss += exam_loss.item()\n",
    "        self.step += 1\n",
    "\n",
    "    def log(self):\n",
    "        logs = f'{self.mode} step {self.step} of {self.loaderlen} trn loss {(self.loss/(self.step)):.4f} '\n",
    "        logs += f'img loss {(self.img_loss/(self.step)):.4f} exam loss {(self.exam_loss/(self.step)):.4f}'\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-03 22:41:15,203 - LSTM - INFO - Start training\n",
      "2020-10-03 22:41:15,212 - LSTM - INFO - --------------------------------------------------\n",
      "2020-10-03 22:41:16,665 - LSTM - INFO - LOOP:train step 2 of 1456 trn loss 0.0914 img loss 0.1514 exam loss 0.0315\n",
      "2020-10-03 22:41:24,073 - LSTM - INFO - LOOP:train step 52 of 1456 trn loss 0.0651 img loss 0.0884 exam loss 0.0419\n",
      "2020-10-03 22:41:31,331 - LSTM - INFO - LOOP:train step 102 of 1456 trn loss 0.0656 img loss 0.0888 exam loss 0.0424\n",
      "2020-10-03 22:41:38,796 - LSTM - INFO - LOOP:train step 152 of 1456 trn loss 0.0665 img loss 0.0914 exam loss 0.0415\n",
      "2020-10-03 22:41:46,290 - LSTM - INFO - LOOP:train step 202 of 1456 trn loss 0.0682 img loss 0.0945 exam loss 0.0418\n",
      "2020-10-03 22:41:53,868 - LSTM - INFO - LOOP:train step 252 of 1456 trn loss 0.0671 img loss 0.0927 exam loss 0.0415\n",
      "2020-10-03 22:42:01,407 - LSTM - INFO - LOOP:train step 302 of 1456 trn loss 0.0661 img loss 0.0908 exam loss 0.0413\n",
      "2020-10-03 22:42:08,963 - LSTM - INFO - LOOP:train step 352 of 1456 trn loss 0.0675 img loss 0.0933 exam loss 0.0418\n",
      "2020-10-03 22:42:16,376 - LSTM - INFO - LOOP:train step 402 of 1456 trn loss 0.0682 img loss 0.0946 exam loss 0.0418\n",
      "2020-10-03 22:42:23,750 - LSTM - INFO - LOOP:train step 452 of 1456 trn loss 0.0677 img loss 0.0938 exam loss 0.0417\n",
      "2020-10-03 22:42:31,305 - LSTM - INFO - LOOP:train step 502 of 1456 trn loss 0.0684 img loss 0.0947 exam loss 0.0420\n",
      "2020-10-03 22:42:38,825 - LSTM - INFO - LOOP:train step 552 of 1456 trn loss 0.0691 img loss 0.0960 exam loss 0.0422\n",
      "2020-10-03 22:42:46,276 - LSTM - INFO - LOOP:train step 602 of 1456 trn loss 0.0694 img loss 0.0964 exam loss 0.0423\n",
      "2020-10-03 22:42:53,488 - LSTM - INFO - LOOP:train step 652 of 1456 trn loss 0.0700 img loss 0.0976 exam loss 0.0424\n",
      "2020-10-03 22:43:01,174 - LSTM - INFO - LOOP:train step 702 of 1456 trn loss 0.0700 img loss 0.0976 exam loss 0.0425\n",
      "2020-10-03 22:43:08,823 - LSTM - INFO - LOOP:train step 752 of 1456 trn loss 0.0691 img loss 0.0959 exam loss 0.0423\n",
      "2020-10-03 22:43:16,602 - LSTM - INFO - LOOP:train step 802 of 1456 trn loss 0.0690 img loss 0.0958 exam loss 0.0423\n",
      "2020-10-03 22:43:23,903 - LSTM - INFO - LOOP:train step 852 of 1456 trn loss 0.0689 img loss 0.0955 exam loss 0.0422\n",
      "2020-10-03 22:43:30,968 - LSTM - INFO - LOOP:train step 902 of 1456 trn loss 0.0689 img loss 0.0957 exam loss 0.0422\n",
      "2020-10-03 22:43:38,729 - LSTM - INFO - LOOP:train step 952 of 1456 trn loss 0.0691 img loss 0.0961 exam loss 0.0422\n",
      "2020-10-03 22:43:46,017 - LSTM - INFO - LOOP:train step 1002 of 1456 trn loss 0.0698 img loss 0.0973 exam loss 0.0423\n",
      "2020-10-03 22:43:53,515 - LSTM - INFO - LOOP:train step 1052 of 1456 trn loss 0.0695 img loss 0.0967 exam loss 0.0423\n",
      "2020-10-03 22:44:01,071 - LSTM - INFO - LOOP:train step 1102 of 1456 trn loss 0.0693 img loss 0.0962 exam loss 0.0423\n",
      "2020-10-03 22:44:08,539 - LSTM - INFO - LOOP:train step 1152 of 1456 trn loss 0.0692 img loss 0.0960 exam loss 0.0423\n",
      "2020-10-03 22:44:16,088 - LSTM - INFO - LOOP:train step 1202 of 1456 trn loss 0.0688 img loss 0.0955 exam loss 0.0422\n",
      "2020-10-03 22:44:23,334 - LSTM - INFO - LOOP:train step 1252 of 1456 trn loss 0.0684 img loss 0.0947 exam loss 0.0421\n",
      "2020-10-03 22:44:30,767 - LSTM - INFO - LOOP:train step 1302 of 1456 trn loss 0.0683 img loss 0.0945 exam loss 0.0421\n",
      "2020-10-03 22:44:38,037 - LSTM - INFO - LOOP:train step 1352 of 1456 trn loss 0.0684 img loss 0.0947 exam loss 0.0422\n",
      "2020-10-03 22:44:45,223 - LSTM - INFO - LOOP:train step 1402 of 1456 trn loss 0.0686 img loss 0.0950 exam loss 0.0421\n",
      "2020-10-03 22:44:52,991 - LSTM - INFO - LOOP:train step 1452 of 1456 trn loss 0.0687 img loss 0.0952 exam loss 0.0421\n",
      "2020-10-03 22:44:53,642 - LSTM - INFO - Exam loss\n",
      "2020-10-03 22:44:53,646 - LSTM - INFO - Image loss\n",
      "2020-10-03 22:44:53,647 - LSTM - INFO - Final loss\n",
      "2020-10-03 22:44:53,648 - LSTM - INFO - Train loss all 0.3477 img 0.3156 exam 0.3791\n",
      "2020-10-03 22:44:53,649 - LSTM - INFO - --------------------------------------------------\n",
      "2020-10-03 22:44:53,650 - LSTM - INFO - Prep test sub...\n",
      "2020-10-03 22:45:48,801 - LSTM - INFO - Exam loss\n",
      "2020-10-03 22:45:48,805 - LSTM - INFO - Image loss\n",
      "2020-10-03 22:45:48,806 - LSTM - INFO - Final loss\n",
      "2020-10-03 22:45:48,808 - LSTM - INFO - Valid loss all 0.6079 img 0.7706 exam 0.4513\n",
      "2020-10-03 22:45:48,905 - LSTM - INFO - --------------------------------------------------\n",
      "2020-10-03 22:45:50,034 - LSTM - INFO - LOOP:train step 2 of 1456 trn loss 0.0299 img loss 0.0378 exam loss 0.0221\n",
      "2020-10-03 22:45:57,314 - LSTM - INFO - LOOP:train step 52 of 1456 trn loss 0.0576 img loss 0.0768 exam loss 0.0385\n",
      "2020-10-03 22:46:04,988 - LSTM - INFO - LOOP:train step 102 of 1456 trn loss 0.0638 img loss 0.0862 exam loss 0.0413\n",
      "2020-10-03 22:46:12,832 - LSTM - INFO - LOOP:train step 152 of 1456 trn loss 0.0667 img loss 0.0921 exam loss 0.0414\n",
      "2020-10-03 22:46:20,338 - LSTM - INFO - LOOP:train step 202 of 1456 trn loss 0.0669 img loss 0.0927 exam loss 0.0412\n",
      "2020-10-03 22:46:27,735 - LSTM - INFO - LOOP:train step 252 of 1456 trn loss 0.0664 img loss 0.0918 exam loss 0.0410\n",
      "2020-10-03 22:46:35,328 - LSTM - INFO - LOOP:train step 302 of 1456 trn loss 0.0686 img loss 0.0956 exam loss 0.0415\n",
      "2020-10-03 22:46:42,774 - LSTM - INFO - LOOP:train step 352 of 1456 trn loss 0.0673 img loss 0.0931 exam loss 0.0415\n",
      "2020-10-03 22:46:50,323 - LSTM - INFO - LOOP:train step 402 of 1456 trn loss 0.0680 img loss 0.0944 exam loss 0.0417\n",
      "2020-10-03 22:46:57,807 - LSTM - INFO - LOOP:train step 452 of 1456 trn loss 0.0688 img loss 0.0956 exam loss 0.0420\n",
      "2020-10-03 22:47:05,332 - LSTM - INFO - LOOP:train step 502 of 1456 trn loss 0.0675 img loss 0.0932 exam loss 0.0418\n",
      "2020-10-03 22:47:12,773 - LSTM - INFO - LOOP:train step 552 of 1456 trn loss 0.0683 img loss 0.0950 exam loss 0.0416\n",
      "2020-10-03 22:47:19,897 - LSTM - INFO - LOOP:train step 602 of 1456 trn loss 0.0685 img loss 0.0952 exam loss 0.0417\n",
      "2020-10-03 22:47:27,704 - LSTM - INFO - LOOP:train step 652 of 1456 trn loss 0.0687 img loss 0.0956 exam loss 0.0417\n",
      "2020-10-03 22:47:35,242 - LSTM - INFO - LOOP:train step 702 of 1456 trn loss 0.0683 img loss 0.0949 exam loss 0.0417\n",
      "2020-10-03 22:47:42,848 - LSTM - INFO - LOOP:train step 752 of 1456 trn loss 0.0673 img loss 0.0929 exam loss 0.0416\n",
      "2020-10-03 22:47:50,272 - LSTM - INFO - LOOP:train step 802 of 1456 trn loss 0.0672 img loss 0.0927 exam loss 0.0417\n",
      "2020-10-03 22:47:57,711 - LSTM - INFO - LOOP:train step 852 of 1456 trn loss 0.0669 img loss 0.0922 exam loss 0.0416\n",
      "2020-10-03 22:48:04,898 - LSTM - INFO - LOOP:train step 902 of 1456 trn loss 0.0663 img loss 0.0911 exam loss 0.0415\n",
      "2020-10-03 22:48:12,732 - LSTM - INFO - LOOP:train step 952 of 1456 trn loss 0.0664 img loss 0.0912 exam loss 0.0416\n",
      "2020-10-03 22:48:20,273 - LSTM - INFO - LOOP:train step 1002 of 1456 trn loss 0.0662 img loss 0.0909 exam loss 0.0416\n",
      "2020-10-03 22:48:27,720 - LSTM - INFO - LOOP:train step 1052 of 1456 trn loss 0.0660 img loss 0.0905 exam loss 0.0415\n",
      "2020-10-03 22:48:35,050 - LSTM - INFO - LOOP:train step 1102 of 1456 trn loss 0.0664 img loss 0.0910 exam loss 0.0417\n",
      "2020-10-03 22:48:42,532 - LSTM - INFO - LOOP:train step 1152 of 1456 trn loss 0.0663 img loss 0.0909 exam loss 0.0418\n",
      "2020-10-03 22:48:49,929 - LSTM - INFO - LOOP:train step 1202 of 1456 trn loss 0.0666 img loss 0.0914 exam loss 0.0418\n",
      "2020-10-03 22:48:56,941 - LSTM - INFO - LOOP:train step 1252 of 1456 trn loss 0.0669 img loss 0.0920 exam loss 0.0419\n",
      "2020-10-03 22:49:04,381 - LSTM - INFO - LOOP:train step 1302 of 1456 trn loss 0.0669 img loss 0.0919 exam loss 0.0419\n",
      "2020-10-03 22:49:12,368 - LSTM - INFO - LOOP:train step 1352 of 1456 trn loss 0.0674 img loss 0.0927 exam loss 0.0420\n",
      "2020-10-03 22:49:19,885 - LSTM - INFO - LOOP:train step 1402 of 1456 trn loss 0.0672 img loss 0.0925 exam loss 0.0420\n",
      "2020-10-03 22:49:27,575 - LSTM - INFO - LOOP:train step 1452 of 1456 trn loss 0.0669 img loss 0.0918 exam loss 0.0420\n",
      "2020-10-03 22:49:28,171 - LSTM - INFO - Exam loss\n",
      "2020-10-03 22:49:28,175 - LSTM - INFO - Image loss\n",
      "2020-10-03 22:49:28,176 - LSTM - INFO - Final loss\n",
      "2020-10-03 22:49:28,177 - LSTM - INFO - Train loss all 0.3421 img 0.3051 exam 0.3783\n",
      "2020-10-03 22:49:28,177 - LSTM - INFO - --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-03 22:49:28,178 - LSTM - INFO - Prep test sub...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-35228a9c5661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prep test sub...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mimg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mystudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlelabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def rsna_criterion_all(y_pred_exam_, \n",
    "                   y_true_exam_, \n",
    "                   y_pred_img_, \n",
    "                   y_true_img_,\n",
    "                   le_study, \n",
    "                   img_wt):\n",
    "    # Groupby \n",
    "    labels = le_study.view(le_study.size(0), 1).expand(-1, 1)\n",
    "    unique_labels, labels_count = labels.unique(dim=0, return_counts=True)\n",
    "    \n",
    "    logger.info('Exam loss')\n",
    "    exam_loss = bce_func_exam(y_pred_exam_, y_true_exam_)\n",
    "    exam_loss = exam_loss.sum(1).unsqueeze(1)\n",
    "    exam_loss = groupBy(exam_loss, labels, unique_labels, labels_count, grptype = 'mean').sum()\n",
    "    exam_wts = torch.tensor(le_study.unique().shape[0]).float()\n",
    "    \n",
    "    logger.info('Image loss')\n",
    "    image_loss = bce_func_img(y_pred_img_, y_true_img_)\n",
    "    image_loss = groupBy(image_loss, labels, unique_labels, labels_count, grptype = 'sum')\n",
    "    qi_all = groupBy(y_true_img_, labels, unique_labels, labels_count, grptype = 'mean')\n",
    "    image_loss = (img_wt * qi_all * image_loss).sum()\n",
    "    img_wts = (img_wt * y_true_img_).sum()\n",
    "    \n",
    "    logger.info('Final loss')\n",
    "    img_loss_out =  image_loss / img_wts\n",
    "    exam_loss_out = exam_loss / exam_wts\n",
    "    final_loss = (image_loss + exam_loss)/(img_wts + exam_wts)\n",
    "    return final_loss , img_loss_out, exam_loss_out\n",
    "\n",
    "\n",
    "def rsna_criterion(y_pred_exam_, \n",
    "                   y_true_exam_, \n",
    "                   y_pred_img_, \n",
    "                   y_true_img_,\n",
    "                   le_study, \n",
    "                   img_wt,\n",
    "                   verbose = False):\n",
    "    #logger.info('Exam loss')\n",
    "    exam_loss = bce_func_exam(y_pred_exam_, y_true_exam_).mean()\n",
    "    #logger.info('Image loss')\n",
    "    img_loss = bce_func_img(y_pred_img_, y_true_img_).mean()\n",
    "    \n",
    "    final_loss = (exam_loss + img_loss)/2\n",
    "        \n",
    "    return final_loss, img_loss, exam_loss\n",
    "\n",
    "\n",
    "logger.info('Start training')\n",
    "for epoch in range(args.epochs):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.train()  \n",
    "    img_wt = torch.tensor(CFG['image_weight']).to(args.device, dtype=torch.float)\n",
    "    trncollect = collectPreds()\n",
    "    valcollect = collectPreds()\n",
    "    trnloss = collectLoss(trnloader, mode = 'train')\n",
    "    valloss = collectLoss(valloader, mode = 'valid')\n",
    "    logger.info(50*'-')\n",
    "    for step, batch in enumerate(trnloader):\n",
    "        img_names, yimg, ystudy, masktrn, lelabels = splitbatch(batch, args.device)\n",
    "        #if yimg.sum()==0: continue\n",
    "        xtrn = batch['emb'].to(args.device, dtype=torch.float)\n",
    "        xtrn = torch.autograd.Variable(xtrn, requires_grad=True)\n",
    "        yimg = torch.autograd.Variable(yimg)\n",
    "        ystudy = torch.autograd.Variable(ystudy)\n",
    "        with autocast():\n",
    "            studylogits, imglogits = model(xtrn, masktrn)#.to(args.device, dtype=torch.float)\n",
    "            yimg, ystudy, lelabels, img_names = unmasklabels(yimg, ystudy, lelabels, img_names, masktrn)\n",
    "            imglogits, studylogits = unmasklogits(imglogits, studylogits, masktrn)\n",
    "            # Loss function\n",
    "            loss, img_loss, exam_loss = rsna_criterion(studylogits, \n",
    "                                                       ystudy, \n",
    "                                                       imglogits, \n",
    "                                                       yimg, \n",
    "                                                       lelabels, \n",
    "                                                       img_wt,\n",
    "                                                       verbose = False)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        trncollect.append(img_names, lelabels, imglogits, studylogits, yimg, ystudy)\n",
    "        trnloss.increment(loss, img_loss, exam_loss)\n",
    "        if step % 50==0: logger.info(f'LOOP:{trnloss.log()}')\n",
    "    trn_loss, trn_img_loss, trn_exam_loss = rsna_criterion_all(*trncollect.concat(args.device), img_wt)\n",
    "    logger.info(f'Train loss all {trn_loss:.4f} img {trn_img_loss:.4f} exam {trn_exam_loss:.4f}')\n",
    "    logger.info(50*'-')\n",
    "    scheduler.step()\n",
    "    logger.info('Prep test sub...')\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(valloader):\n",
    "        img_names, yimg, ystudy, maskval, lelabels = splitbatch(batch, args.device)\n",
    "        xval = batch['emb'].to(args.device, dtype=torch.float)\n",
    "        studylogits, imglogits = model(xval, maskval)#.to(args.device, dtype=torch.float)\n",
    "        # Repeat studies to have a prediction for every image\n",
    "        yimg, ystudy, lelabels, img_names = unmasklabels(yimg, ystudy, lelabels, img_names, maskval)\n",
    "        imglogits, studylogits = unmasklogits(imglogits, studylogits, maskval)\n",
    "        loss, img_loss, exam_loss = rsna_criterion(studylogits, \n",
    "                                                   ystudy, \n",
    "                                                   imglogits, \n",
    "                                                   yimg, \n",
    "                                                   lelabels, \n",
    "                                                   img_wt)\n",
    "        valcollect.append(img_names, lelabels, imglogits, studylogits, yimg, ystudy)\n",
    "        valloss.increment(loss, img_loss, exam_loss)\n",
    "    val_loss, val_img_loss, val_exam_loss = rsna_criterion_all(*valcollect.concat(args.device), img_wt)\n",
    "    logger.info(f'Valid loss all {val_loss:.4f} img {val_img_loss:.4f} exam {val_exam_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trncollect.series('img_names').shape)\n",
    "print(trncollect.series('study_labels').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myseries(collect, feat):\n",
    "    return torch.sigmoid(collect.series(feat).float().cpu()).numpy()\n",
    "\n",
    "trnpreds = pd.DataFrame(np.concatenate((myseries(trncollect, 'img_preds'), \n",
    "                    myseries(trncollect, 'study_preds')), 1),\n",
    "                    columns = CFG['image_target_cols']+CFG['exam_target_cols'], \n",
    "                    index = trncollect.series('img_names'))\n",
    "valpreds = pd.DataFrame(np.concatenate((myseries(valcollect, 'img_preds'), \n",
    "                    myseries(valcollect, 'study_preds')), 1),\n",
    "                    columns = CFG['image_target_cols']+CFG['exam_target_cols'], \n",
    "                    index = valcollect.series('img_names'))   \n",
    "valpreds.hist(figsize = (25,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnpreds.hist(figsize = (25,25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valpreds.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valpreds.tail(1).index)\n",
    "print(xval[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trnpreds.tail(1).index)\n",
    "print(xtrn[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = datals[0]\n",
    "logger.info(f'File load : {f}')\n",
    "dfname, embname, imgnm = f, f.replace('.data.pk', '.npz'), f.replace('.data.pk', '.imgnames.pk')\n",
    "datadf = pd.read_pickle(dfname)\n",
    "embmat = np.load(embname)['arr_0']\n",
    "embmat = embmat[np.where(datadf.SOPInstanceUID=='32ec58af84d9')[0]]\n",
    "embmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = datals[1]\n",
    "logger.info(f'File load : {f}')\n",
    "dfname, embname, imgnm = f, f.replace('.data.pk', '.npz'), f.replace('.data.pk', '.imgnames.pk')\n",
    "datadf = pd.read_pickle(dfname)\n",
    "embmat = np.load(embname)['arr_0']\n",
    "embmat = embmat[np.where(datadf.SOPInstanceUID=='dba5502f56b7')[0]]\n",
    "embmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masktrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval.mean(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn.mean(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
